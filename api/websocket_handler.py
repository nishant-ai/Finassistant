"""
WebSocket handler for real-time agent streaming

This module provides WebSocket support for streaming agent responses in real-time.
Users can see what the agent is doing step-by-step, similar to ChatGPT/Claude.ai.
"""

import asyncio
import json
import logging
from typing import Optional, Callable
from datetime import datetime, timezone
from fastapi import WebSocket, WebSocketDisconnect
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)


class StreamCallback:
    """Callback handler for capturing agent events and streaming them via WebSocket"""

    def __init__(self, websocket: WebSocket):
        self.websocket = websocket
        self.is_connected = True

    async def send_event(self, event_type: str, data: dict):
        """Send an event to the WebSocket client"""
        if not self.is_connected:
            return

        try:
            await self.websocket.send_json({
                "type": event_type,
                "data": data,
                "timestamp": datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')
            })
        except Exception as e:
            logger.error(f"Error sending WebSocket event: {e}")
            self.is_connected = False

    async def on_agent_start(self, mode: str, query: str):
        """Called when agent starts processing"""
        await self.send_event("agent_start", {
            "mode": mode,
            "query": query,
            "status": f"ðŸ¤– Starting {mode} mode..."
        })

    async def on_agent_step(self, step: str, details: Optional[str] = None):
        """Called on each agent step"""
        await self.send_event("agent_step", {
            "step": step,
            "details": details
        })

    async def on_tool_call(self, tool_name: str, tool_input: dict):
        """Called when a tool is invoked"""
        await self.send_event("tool_call", {
            "tool": tool_name,
            "input": tool_input,
            "status": "running"
        })

    async def on_tool_result(self, tool_name: str, result: str, success: bool = True):
        """Called when a tool returns a result"""
        await self.send_event("tool_result", {
            "tool": tool_name,
            "success": success,
            "result_preview": result[:200] + "..." if len(result) > 200 else result
        })

    async def on_llm_start(self, prompts: list):
        """Called when LLM starts generating"""
        await self.send_event("llm_start", {
            "status": "ðŸ’­ Thinking..."
        })

    async def on_llm_token(self, token: str):
        """Called for each token generated by LLM"""
        await self.send_event("llm_token", {
            "token": token
        })

    async def on_llm_end(self, response: str):
        """Called when LLM finishes"""
        await self.send_event("llm_end", {
            "status": "âœ“ Complete"
        })

    async def on_agent_complete(self, result: str, metadata: dict):
        """Called when agent completes processing"""
        await self.send_event("agent_complete", {
            "result": result,
            "metadata": metadata
        })

    async def on_error(self, error: str, error_type: str):
        """Called when an error occurs"""
        await self.send_event("error", {
            "error": error,
            "error_type": error_type
        })


class ConnectionManager:
    """Manages WebSocket connections"""

    def __init__(self):
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        """Accept a WebSocket connection"""
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket connected: {client_id}")

    def disconnect(self, client_id: str):
        """Remove a WebSocket connection"""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"WebSocket disconnected: {client_id}")

    async def send_message(self, client_id: str, message: dict):
        """Send a message to a specific client"""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json(message)
            except Exception as e:
                logger.error(f"Error sending to {client_id}: {e}")
                self.disconnect(client_id)


# Global connection manager instance
manager = ConnectionManager()


async def stream_agent_response(
    websocket: WebSocket,
    query: str,
    mode: str,
    session_id: Optional[str],
    user_id: str,
    save_history: bool,
    run_agent_func: Callable
):
    """
    Stream agent response via WebSocket with real-time updates.

    Args:
        websocket: WebSocket connection
        query: User query
        mode: "chat" or "report"
        session_id: Optional session ID
        user_id: User identifier
        save_history: Whether to save to database
        run_agent_func: The agent function to run (should be the processing function)
    """
    callback = StreamCallback(websocket)

    try:
        # Send initial start event
        await callback.on_agent_start(mode, query)

        # Import here to avoid circular imports
        from api.app import _process_agent_query

        # Send processing steps
        await callback.on_agent_step(
            "Initializing",
            f"Preparing {mode} mode analysis..."
        )

        # If creating/loading session
        if save_history:
            await callback.on_agent_step(
                "Session",
                "Loading conversation history..." if session_id else "Creating new session..."
            )

        # Notify that agent is running
        await callback.on_agent_step(
            "Processing",
            "Analyzing your query and selecting appropriate tools..."
        )

        # Run the agent (this will be in a thread pool from our Phase 1 fix)
        # We'll intercept the agent execution to add more streaming
        result = await run_agent_func(
            query=query,
            query_type=mode,
            verbose=False,
            session_id=session_id,
            user_id=user_id,
            save_to_history=save_history
        )

        # Stream the final result token by token for smooth effect
        response_text = result.result

        # Send tokens in chunks for smooth streaming effect
        await callback.on_llm_start([])

        # Stream response word by word
        words = response_text.split()
        for i, word in enumerate(words):
            if not callback.is_connected:
                break

            # Send word with space (except last word)
            token = word if i == len(words) - 1 else word + " "
            await callback.on_llm_token(token)

            # Small delay for smooth streaming effect (adjust as needed)
            await asyncio.sleep(0.02)

        await callback.on_llm_end(response_text)

        # Send completion event
        await callback.on_agent_complete(
            result=response_text,
            metadata={
                "session_id": result.metadata.get("session_id"),
                "execution_time": result.metadata.get("execution_time_seconds"),
                "mode": mode
            }
        )

    except WebSocketDisconnect:
        logger.info("WebSocket disconnected during streaming")
        callback.is_connected = False
    except Exception as e:
        logger.error(f"Error in stream_agent_response: {e}", exc_info=True)
        await callback.on_error(
            error=str(e),
            error_type=type(e).__name__
        )
        raise
